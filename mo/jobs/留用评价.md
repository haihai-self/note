### 项目/工作及结果

* 参与了特征重要性项目, 项目的目标是在指标不降的情况下减少模型的特征, 我在项目中承担的职责是算法的调研与实现, 主要调研了传统特征工程中决策树、mRMR等方法以及深度学习中扰动分析、droprank等方法. 通过实验分析发现, 传统的特征工程方法在大数据深度学习模型中并不适用, 同时实验发现droprank等一些深度学习特征工程方法能比较好的适配我们的具体业务场景, 并将这些算法在我们的具体业务场景中落地. 最终在闪购模型上删除了43%的离散特征以及26%的连续特征后, 进行线上实验指标不降.
* 参与了CPU加速项目, 项目的目标是发掘模型的并行性, 通过tensorflow的profile工具进行性能分析, 发现外卖模型中存在一些使用不合理的op算子导致模型无法充分理由现有算力. 通过改写合并这些不合理的op算子, 使得模型最终的性能提升18%
* 参与了tensorflow平台升级项目, 目标是将现有的tf1.0.8升级到tf1.15, 同时使自己快速熟悉集团内部开发的工具链. 在升级tf包过程中, 发现了现有项目中的一些bug并对其进行了修复, 同时新增了一些常用的如debug, 迁移学习等模块. 通过升级tf包获得了15%左右的性能提升.

### 项目/工作中收获

最大的收获是认识的一群有趣且能力强悍的小伙伴, 初到美团对业务以及模型都还不熟悉, 在郭霖, 周俊文以及同组其他一些小伙伴的帮助下, 通过参与tf平台升级的项目, 使我快速融入到了项目组中, 并学习到了项目组内部使用的各种工具, 了解到了大家的工作流程, 在相对来说比较枯燥的工具学习的过程中, 参与到了具体的项目中, 并取得了一定的成果, 这个过程给予了我比较大的信心,  迈出了坚实的第一步. 接下来是参与了cpu优化的项目, 这个项目使我相对深入的了解tensorflow构图的思想以及运行的机制, 为我之后进行特征优化分析打下了比较好的基础. 最后模型瘦身项目中, 学习到了一系列深度学习中特征工程的方法论, 从学术界一系列特征分析方法中, 筛选出了droprank等比较符合大规模深度学习的方法, 同时结合我们的具体业务, 将算法成功落地到了我们具体业算法模型中, 在闪购模型中优化了43%的离散特征以及26%的连续特征的同时指标不降, 取得效果的同时获得了极大成就感. 

在参与项目以及不断取得正反馈这样的过程中, 慢慢积累起了技术自信, 深入了解了深度学习如何在推荐搜索领域落地, 了解了美团的企业文化以及从周围的小伙伴身上学习到了很多高效开发的良好习惯, 最后再次感谢郭霖以及周俊文两位老师傅不厌其烦的耐心指导, 感谢感恩!

### 未来发展规划

在12年左右, 由于算力大幅提升导致深度学习的兴起,  一系列的算法模型井喷式迸发的同时, 也极大的促进了深度学习在搜索推荐算法的发展. 但随着模型以及数据量的增加, 算力越来越成为我们发展的瓶颈. 具体到我们实际的推荐场景中, 一次模型的训练使用2000个cpu大概需要2天的时间, 且随着模型以及数据量的增加, 迭代周期将会进一步的增长, 如果不加以创新、优化, 算力将会成为算法指标提升的主要瓶颈. 为了解决这样的问题, 异构计算成为了各大公司的主要选择, 包括字节的BytePS平台, 快手的Persia平台等等. 算法联合算力优化是异构计算的主要方向, 而我自己本身研究生的科研方向也比较偏向于异构计算, 异构计算如何在搜索推荐领域落地也正是我们组内最近需要攻克的难点之一, 借着这个机会向组内各位前辈学习, 我觉得对自己的发展有非常好的帮助. 同时深耕技术前沿, 积极了解包括CV, NLP等深度学习技术在推荐搜索领域上创新性的应用, 与大家多多交流不断充电!

### 其他补充

[实习总结文档](https://km.sankuai.com/page/1093158395)

[模型瘦身总结文档](https://km.sankuai.com/page/1086217094)

[CPU加速总结文档](https://km.sankuai.com/page/961097396)

[tf模型迁移文档](https://km.sankuai.com/page/940476724)





transfer frozen http://zw03-data-hdp-rm-trainingha01.sankuai.com:8088/proxy/application_1628503387247_1158638/

transfer unfrozen http://zw03-data-hdp-rm-trainingha01.sankuai.com:8088/proxy/application_1629368832660_309658/

