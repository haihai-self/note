Approximate arithmetic circuits have widely been investigated to pursue high-performance and energy-efficient hardware designs for error-tolerant applications such as DNNs. As a key feature, the accuracy of an approximate design has been statistically evaluated by using many error metrics. However, approximate designs can hardly been distinguished by using individual error metrics; thus, selecting an appropriate approximate design for an application with a specific accuracy constraint is time-consuming even intractable. In this paper, error metrics for approximate multipliers (AMs) are extensively studied and ordered by their importance to the application results based on the Dropout Feature Ranking criterion. Application-specific model are then established based on metric combinations and trained accuracy. By using these models, the AMs can be correctly classified for specific applications with accuracy over 90%. Therefore, the proposed error models can effectively advise the AM selection for specific and general applications. Also, the results show that through the retraining of AMs, the problem of over-fitting is solved to a certain extent. 

Application-specific and general error models are then established based on the highly relevant error metric combinations and machine learning technologies. By using these models, the AMs can be correctly classified for specific and general applications with an accuracy over 90\%. Therefore, the proposed error models can effectively advise the AM selection for specific and general applications. Also, the results show that the accuracy boost of an approximate application converges as the complexity of the processing data or neural network reaches to a certain degree. Therefore, the proposed error models can effectively advise the approximate multiplier selection for error-tolerant applications.

